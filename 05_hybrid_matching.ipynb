{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3MB38bxuo7A2x7BhPNC7Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5tapNhpdbSdn","executionInfo":{"status":"ok","timestamp":1745995323598,"user_tz":-330,"elapsed":19,"user":{"displayName":"AR Y","userId":"12465724081765732878"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import pickle\n","from collections import defaultdict\n","from glob import glob"]},{"cell_type":"code","source":["def build_ili(descriptor_folder):\n","    ili = defaultdict(list)\n","    for file in glob(os.path.join(descriptor_folder, \"*.npy\")):\n","        desc = np.load(file)\n","        key = tuple(desc)  # Binarized HOG\n","        ili[key].append(file)\n","    with open(\"ili_index.pkl\", \"wb\") as f:\n","        pickle.dump(ili, f)\n","    print(f\"ILI index built with {len(ili)} unique keys.\")"],"metadata":{"id":"GqhnvNWDbWp5","executionInfo":{"status":"ok","timestamp":1745995350518,"user_tz":-330,"elapsed":10,"user":{"displayName":"AR Y","userId":"12465724081765732878"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def pqhog_search(test_image_path, template_folder, ili_path, top_k=5):\n","    from sklearn.preprocessing import Binarizer\n","    from skimage.feature import hog\n","    import cv2\n","\n","    with open(ili_path, \"rb\") as f:\n","        ili_index = pickle.load(f)\n","\n","    image = cv2.imread(test_image_path)\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Extract PQ-HOG\n","    features, _ = hog(gray, pixels_per_cell=(8,8), cells_per_block=(1,1),\n","                      orientations=9, visualize=True)\n","    binarized = Binarizer(threshold=0).fit_transform(features.reshape(1, -1)).flatten()\n","    query_key = tuple(binarized)\n","\n","    # Simple matching: Hamming distance between binary vectors\n","    def hamming_dist(a, b):\n","        return np.sum(np.array(a) != np.array(b))\n","\n","    distances = []\n","    for key in ili_index:\n","        d = hamming_dist(query_key, key)\n","        distances.append((d, key))\n","\n","    distances.sort()\n","    top_keys = [key for _, key in distances[:top_k]]\n","\n","    matches = []\n","    for key in top_keys:\n","        for path in ili_index[key]:\n","            matches.append(path)\n","    return matches[:top_k]\n"],"metadata":{"id":"0NAPqtJMbWsp","executionInfo":{"status":"ok","timestamp":1745995359499,"user_tz":-330,"elapsed":49,"user":{"displayName":"AR Y","userId":"12465724081765732878"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def hybrid_detect(test_image_path, template_folder, descriptor_folder, ili_path, output_path):\n","    matches = pqhog_search(test_image_path, template_folder, ili_path)\n","\n","    test_img = cv2.imread(test_image_path)\n","    eq, bin_img = preprocess_roi(test_img)\n","    best_fit = -1\n","    best_result = None\n","    best_template = None\n","\n","    for match_path in matches:\n","        template = cv2.imread(match_path)\n","        result, score = run_ga(template, eq, bin_img, img_size=eq.shape[::-1])\n","        if result and score > best_fit:\n","            best_fit = score\n","            best_result = result\n","            best_template = template\n","\n","    if best_result:\n","        filename = os.path.basename(test_image_path)\n","        overlay_and_save(test_img, best_template, best_result, os.path.join(output_path, filename))\n","        print(f\"✅ Saved best hybrid match for {filename} with fitness {best_fit:.2f}\")\n","    else:\n","        print(\"⚠️ No valid match found.\")\n"],"metadata":{"id":"FJk6ucl-bTk4","executionInfo":{"status":"ok","timestamp":1745995368585,"user_tz":-330,"elapsed":3,"user":{"displayName":"AR Y","userId":"12465724081765732878"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Step 1: Build the ILI index (run once)\n","build_ili(\"pqhog_descriptors/test\")\n","\n","# Step 2: Run on one image (test hybrid matching)\n","hybrid_detect(\n","    test_image_path=\"test_images/example.jpg\",\n","    template_folder=\"templates\",\n","    descriptor_folder=\"pqhog_descriptors/test\",\n","    ili_path=\"ili_index.pkl\",\n","    output_path=\"results\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"gB78jfL-bTnh","executionInfo":{"status":"error","timestamp":1745995382029,"user_tz":-330,"elapsed":1393,"user":{"displayName":"AR Y","userId":"12465724081765732878"}},"outputId":"90fe64d3-6fba-4a68-9621-a30e282979bb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["ILI index built with 0 unique keys.\n"]},{"output_type":"error","ename":"error","evalue":"OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4cf3e9a79bf6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 2: Run on one image (test hybrid matching)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m hybrid_detect(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_image_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test_images/example.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtemplate_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"templates\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-adbea49b068b>\u001b[0m in \u001b[0;36mhybrid_detect\u001b[0;34m(test_image_path, template_folder, descriptor_folder, ili_path, output_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptor_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mili_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpqhog_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mili_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-dce5e914e064>\u001b[0m in \u001b[0;36mpqhog_search\u001b[0;34m(test_image_path, template_folder, ili_path, top_k)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Extract PQ-HOG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"cell_type":"code","source":["import random"],"metadata":{"id":"UGbhSzldhtMT","executionInfo":{"status":"ok","timestamp":1745996936682,"user_tz":-330,"elapsed":11,"user":{"displayName":"AR Y","userId":"12465724081765732878"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# hybrid_seatbelt_matching.py\n","\n","import os\n","import cv2\n","import numpy as np\n","from glob import glob\n","import pickle\n","from collections import defaultdict\n","from skimage.feature import hog\n","from skimage.transform import resize, rotate\n","from sklearn.preprocessing import Binarizer\n","\n","# ---------------------- PQ-HOG + ILI ----------------------\n","def extract_pqhog(image):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    features, _ = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(1, 1),\n","                      orientations=9, visualize=True, block_norm='L2-Hys')\n","    binarized = Binarizer(threshold=0).fit_transform(features.reshape(1, -1)).flatten()\n","    return binarized\n","\n","def generate_pqhog_descriptors(roi_folder, save_folder):\n","    os.makedirs(save_folder, exist_ok=True)\n","    for path in glob(os.path.join(roi_folder, \"*.jpg\")):\n","        image = cv2.imread(path)\n","        if image is None: continue\n","        descriptor = extract_pqhog(image)\n","        name = os.path.basename(path).replace(\".jpg\", \"_pqhog.npy\")\n","        np.save(os.path.join(save_folder, name), descriptor)\n","\n","def build_ili_index(descriptor_folder, save_path=\"ili_index.pkl\"):\n","    ili = defaultdict(list)\n","    for file in glob(os.path.join(descriptor_folder, \"*.npy\")):\n","        desc = np.load(file)\n","        key = tuple(desc)\n","        ili[key].append(file)\n","    with open(save_path, \"wb\") as f:\n","        pickle.dump(ili, f)\n","\n","# ---------------------- Preprocessing ----------------------\n","def preprocess_roi(roi):\n","    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n","    eq = cv2.equalizeHist(gray)\n","    bin_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n","                                     cv2.THRESH_BINARY, 23, 5)\n","    return eq, bin_img\n","\n","# ---------------------- Fitness & GA ----------------------\n","def compute_fitness(template_img, eq_img, bin_img, tx, ty, sx, sy, theta):\n","    h, w = template_img.shape[:2]\n","    th, tw = int(h * sy), int(w * sx)\n","    temp = resize(template_img, (th, tw), anti_aliasing=True)\n","    temp = rotate(temp, theta, resize=False)\n","    temp = (temp * 255).astype(np.uint8)\n","    roi_h, roi_w = eq_img.shape\n","    if tx + tw > roi_w or ty + th > roi_h:\n","        return 0\n","    eq_crop = eq_img[ty:ty+th, tx:tx+tw]\n","    bin_crop = bin_img[ty:ty+th, tx:tx+tw]\n","    third = th // 3\n","    if third == 0: return 0\n","    a = np.mean(eq_crop[0:third])\n","    b = np.mean(eq_crop[third:2*third])\n","    c = np.mean(eq_crop[2*third:])\n","    O1 = (abs(a - b) + abs(c - b)) / 2\n","    awht = np.sum(bin_crop[0:third] == 255) / (bin_crop[0:third].size + 1e-5)\n","    bblk = np.sum(bin_crop[third:2*third] == 0) / (bin_crop[third:2*third].size + 1e-5)\n","    cwht = np.sum(bin_crop[2*third:] == 255) / (bin_crop[2*third:].size + 1e-5)\n","    O2 = (awht + cwht + 2 * bblk) / 4\n","    return O1 + O2\n","\n","def run_ga(template, eq_img, bin_img, img_size, pop_size=30, gen_size=30):\n","    wtgt, htgt = img_size\n","    if wtgt <= 46 or htgt <= 18:\n","        return None, 0\n","    population = [(\n","        np.random.randint(0, wtgt - 46),\n","        np.random.randint(0, htgt - 18),\n","        np.random.uniform(0.8, 1.2),\n","        np.random.uniform(0.8, 1.2),\n","        np.random.uniform(-30, 0)\n","    ) for _ in range(pop_size)]\n","\n","    best_fit = -1\n","    best_ind = None\n","    for _ in range(gen_size):\n","        fitnesses = []\n","        for ind in population:\n","            tx, ty, sx, sy, theta = ind\n","            f = compute_fitness(template, eq_img, bin_img, tx, ty, sx, sy, theta)\n","            fitnesses.append(f)\n","            if f > best_fit:\n","                best_fit = f\n","                best_ind = ind\n","        parents = [population[i] for i in np.argsort(fitnesses)[-pop_size//5:]]\n","        new_population = []\n","        while len(new_population) < pop_size:\n","            p1, p2 = random.sample(parents, 2)\n","            child = (\n","                np.random.choice([p1[0], p2[0]]),\n","                np.random.choice([p1[1], p2[1]]),\n","                (p1[2] + p2[2]) / 2,\n","                (p1[3] + p2[3]) / 2,\n","                (p1[4] + p2[4]) / 2\n","            )\n","            if np.random.rand() < 0.1:\n","                child = (\n","                    child[0] + np.random.randint(-5, 5),\n","                    child[1] + np.random.randint(-5, 5),\n","                    child[2] * np.random.uniform(0.95, 1.05),\n","                    child[3] * np.random.uniform(0.95, 1.05),\n","                    child[4] + np.random.uniform(-2, 2)\n","                )\n","            new_population.append(child)\n","        population = new_population\n","    return best_ind, best_fit\n","\n","# ---------------------- Overlay and Save ----------------------\n","def overlay_and_save(test_img, template, params, out_path):\n","    tx, ty, sx, sy, theta = params\n","    th, tw = template.shape[:2]\n","    h, w = int(th * sy), int(tw * sx)\n","    resized = resize(template, (h, w), anti_aliasing=True)\n","    rotated = rotate(resized, theta, resize=False)\n","    rotated = (rotated * 255).astype(np.uint8)\n","    if len(rotated.shape) == 2:\n","        rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2BGR)\n","    overlay = test_img.copy()\n","    if ty + h > overlay.shape[0] or tx + w > overlay.shape[1]:\n","        return\n","    cv2.rectangle(overlay, (tx, ty), (tx + w, ty + h), (0, 255, 0), 2)\n","    roi = overlay[ty:ty+h, tx:tx+w]\n","    overlay[ty:ty+h, tx:tx+w] = cv2.addWeighted(roi, 0.5, rotated, 0.5, 0)\n","    cv2.imwrite(out_path, overlay)\n","\n","# ---------------------- Hybrid Detector ----------------------\n","def hybrid_detect_batch(image_folder, template_path, output_path):\n","    os.makedirs(output_path, exist_ok=True)\n","    template = cv2.imread(template_path)\n","    if template is None:\n","        print(\"Template load failed.\")\n","        return\n","\n","    for img_path in glob(os.path.join(image_folder, \"*.jpg\")):\n","        test_img = cv2.imread(img_path)\n","        if test_img is None:\n","            print(f\"⚠️ Failed to load {img_path}\")\n","            continue\n","        eq, bin_img = preprocess_roi(test_img)\n","        params, score = run_ga(template, eq, bin_img, img_size=eq.shape[::-1])\n","        if params:\n","            result_path = os.path.join(output_path, os.path.basename(img_path))\n","            overlay_and_save(test_img, template, params, result_path)\n","            print(f\"✅ {os.path.basename(img_path)} → score {score:.2f}\")\n","        else:\n","            print(f\"⚠️ No valid match for {img_path}\")\n"],"metadata":{"id":"2I9FVZTDbTqa","executionInfo":{"status":"ok","timestamp":1745997056503,"user_tz":-330,"elapsed":50,"user":{"displayName":"AR Y","userId":"12465724081765732878"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"me1dm_K1grOF","executionInfo":{"status":"ok","timestamp":1745996692973,"user_tz":-330,"elapsed":24079,"user":{"displayName":"AR Y","userId":"12465724081765732878"}},"outputId":"456d04bd-73a4-4d91-c96e-70f5eb062bf7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["hybrid_detect_batch(\n","    image_folder=\"/content/cropped_rois/test\",\n","    template_path=\"template.jpg\",\n","    output_path=\"results\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":842},"id":"G_fn0N9BbTsq","executionInfo":{"status":"error","timestamp":1745998230169,"user_tz":-330,"elapsed":25082,"user":{"displayName":"AR Y","userId":"12465724081765732878"}},"outputId":"5c6370bc-7871-4dca-bfac-3adb303f51b4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ 05-09-04_jpg.rf.3697cd52aa696b844db6277265a9bf25_person-noseatbelt_2.jpg → score 46.63\n","✅ 1625227981033_jpg.rf.a9131630836bf994d5a538f55a584a0d_person-seatbelt_2.jpg → score 60.26\n","⚠️ No valid match for /content/cropped_rois/test/05-12-35_jpg.rf.ed26d1f80295a6e15a2dcda065b7a83d_person-noseatbelt_1.jpg\n","✅ 945_png.rf.a087b9d0e32ea00f5b1ee9600c407a4f_person-noseatbelt_1.jpg → score 28.77\n","✅ 1625227980786_jpg.rf.44469331538f889d2b7c4266285f6f07_person-seatbelt_1.jpg → score 54.68\n","✅ frame_001152iiii-14-_jpg.rf.7ed7e63f855cac3da1b30027ccb6a160_person-seatbelt_0.jpg → score 43.72\n","✅ wwframe_001044-23-_jpg.rf.29f8acc748b79dc2aa35d067e26a77ab_windshield_0.jpg → score 74.82\n","✅ frame_001296kkkkkk-16-_jpg.rf.28fa2a05ac7a1010665267139268aacf_person-seatbelt_1.jpg → score 29.55\n","✅ 1_CAR_13-52-25-265_jpg.rf.569639aed27d3e4952fabadf3931afe8_person-seatbelt_0.jpg → score 109.61\n","✅ 1625227981116_jpg.rf.5324f5aba1261c8be3577ea53b60e34f_person-seatbelt_1.jpg → score 71.02\n","✅ 703_png_jpg.rf.67d52975664ee040448137ec31b600c6_windshield_3.jpg → score 84.28\n","⚠️ No valid match for /content/cropped_rois/test/911_png_jpg.rf.3204b3ef13a8b2350747f43face18dc1_person-noseatbelt_1.jpg\n","✅ 997_png_jpg.rf.0b355584c80753ce43a3291c70f5a66e_windshield_0.jpg → score 50.13\n","✅ 1625227980842_jpg.rf.d7f7e2a116271d7deebb114e65198317_windshield_0.jpg → score 87.74\n","✅ 04-45-27_jpg.rf.fd850f2b232de3a0a15ca451be8079a9_windshield_0.jpg → score 101.91\n","✅ 1625227980813_jpg.rf.94398ff8fbaf286cd9dc130e49de7572_person-noseatbelt_2.jpg → score 56.33\n","✅ 1625227981085_jpg.rf.75d26c91e3bccc588a0ffa90ae707165_person-seatbelt_3.jpg → score 48.42\n","⚠️ No valid match for /content/cropped_rois/test/872_png_jpg.rf.f99caa9f5d557caff8cf3b9e3a6941fb_person-noseatbelt_2.jpg\n","✅ 1625227981116_jpg.rf.c69a1a7a1d4fe17e00b79eacb0e57e87_person-seatbelt_1.jpg → score 52.24\n","✅ frame_001296kkkkkk-16-_jpg.rf.28fa2a05ac7a1010665267139268aacf_windshield_0.jpg → score 85.25\n","✅ 04-15-28_jpg.rf.8e651f431f797afb341b30d5706ca03d_windshield_0.jpg → score 97.49\n","✅ frame_001296kkkkkk-1-_jpg.rf.575c71c9df2abd0a2b497204c0401988_windshield_0.jpg → score 84.05\n","✅ 1625227981149_jpg.rf.fcb67a57fcfa5c2280501b2b88435e47_windshield_3.jpg → score 85.92\n","✅ 883_png_jpg.rf.073dd8463d0cacae7a08edd69c2f2e81_windshield_0.jpg → score 74.76\n","✅ 911_png_jpg.rf.3204b3ef13a8b2350747f43face18dc1_windshield_0.jpg → score 73.25\n","✅ 1625227981126_jpg.rf.50612f67b18a0f024c6566e11cd0e06d_person-seatbelt_1.jpg → score 38.67\n","✅ 1_CAR_06-14-21-775_jpg.rf.b7142929202d537399f21681781a9f21_person-noseatbelt_1.jpg → score 183.83\n","✅ 1625227981208_jpg.rf.dbe1523d51f412794a51fb9903899f47_person-seatbelt_1.jpg → score 69.99\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f3deae888ed8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m hybrid_detect_batch(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimage_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/cropped_rois/test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemplate_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"template.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m<ipython-input-16-39499cdb50ac>\u001b[0m in \u001b[0;36mhybrid_detect_batch\u001b[0;34m(image_folder, template_path, output_path)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ga\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-39499cdb50ac>\u001b[0m in \u001b[0;36mrun_ga\u001b[0;34m(template, eq_img, bin_img, img_size, pop_size, gen_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meq_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mfitnesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-39499cdb50ac>\u001b[0m in \u001b[0;36mcompute_fitness\u001b[0;34m(template_img, eq_img, bin_img, tx, ty, sx, sy, theta)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mthird\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq_crop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq_crop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq_crop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mO1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3594\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3596\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3597\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# prompt: zip file\n","\n","import zipfile\n","import os\n","\n","def zip_files(directory_to_zip, zip_filename):\n","  \"\"\"Zips a directory.\n","\n","  Args:\n","    directory_to_zip: The directory to zip.\n","    zip_filename: The name of the output zip file.\n","  \"\"\"\n","\n","  with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","    for root, _, files in os.walk(directory_to_zip):\n","      for file in files:\n","        file_path = os.path.join(root, file)\n","        zipf.write(file_path, arcname=os.path.relpath(file_path, directory_to_zip))\n","  print(f\"Successfully zipped {directory_to_zip} to {zip_filename}\")\n","\n","# Example usage (replace with your actual directory and desired zip file name)\n","zip_files(\"results\", \"results.zip\") # zips the current directory\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iv9HVHh8mr9A","executionInfo":{"status":"ok","timestamp":1745998271708,"user_tz":-330,"elapsed":417,"user":{"displayName":"AR Y","userId":"12465724081765732878"}},"outputId":"094a7822-7f91-41d4-d4e0-d2385cba5823"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully zipped results to results.zip\n"]}]}]}